{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## jupyter notebook に最初に記述tenplate\n",
    "\n",
    "\"\"\"\n",
    "2021.09.27 今回参考にしたものについて\n",
    "https://qiita.com/ku_a_i/items/0ea4b93d767ce7c83145\n",
    "\n",
    "2021.09.29 - Res-Net34について\n",
    "https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "\n",
    "\"\"\"\n",
    "### ------------------------------------------------\n",
    "# basic-module\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os,re,glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "# sori -module\n",
    "# sys.path.append('/home/ysorimachi/tool')\n",
    "# from getErrorValues import me,rmse,mae,r2 #(x,y)\n",
    "# from convSokuhouData import conv_sfc #(df, ave=minutes,hour)\n",
    "\n",
    "# #---------------------------------------------------\n",
    "# import subprocess\n",
    "# import requests\n",
    "# #--------------------------\n",
    "# import pickle\n",
    "# import gzip\n",
    "# from pathlib import Path\n",
    "\n",
    "# deep learning modules \n",
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary #torchinfoはニューラルネットの中身を見れるのでおすすめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考の資料について\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "def load_df(path, isDAY=True):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df[\"dd\"] = df[\"time\"].apply(lambda x: x.strftime(\"%Y%m%d\"))\n",
    "    df[\"hh\"] = df[\"time\"].apply(lambda x: x.strftime(\"%H\"))\n",
    "    \n",
    "    if isDAY:\n",
    "        df = df.groupby(\"dd\").agg({\"DEMAND(10^4kW)\" : \"mean\"})\n",
    "    return df\n",
    "\n",
    "def plot_df(df,_col):\n",
    "    f,ax = plt.subplots(figsize=(18,8))\n",
    "    for c in _col:\n",
    "        ax.plot(df[c],label=c)\n",
    "    \n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def cut_time(df,st,ed=None):\n",
    "    if ed:\n",
    "        return df[(df[\"time\"]>=st)&(df[\"time\"]<=ed)]\n",
    "    else:\n",
    "        return df[df[\"time\"]>=st]\n",
    "\n",
    "def move_ave(df,col,lag=7):\n",
    "    new_col  = f\"MA{lag}_{col}\"\n",
    "    df[new_col]= df[col].rolling(lag).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch ResNet pretrained model \n",
    "\"\"\"\n",
    "import torchvision\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# model = torchvision.models.resnet18(pretrained= True)\n",
    "# model = torchvision.models.resnet34(pretrained= True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "def load_resnet(N=18,pretrained=True):\n",
    "    if N==18:\n",
    "        return torchvision.models.resnet18(pretrained= pretrained)\n",
    "    if N==34:\n",
    "        return torchvision.models.resnet34(pretrained= pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pic_imshow(img):\n",
    "    if type(img)== torch.Tensor:\n",
    "        img = img.to('cpu').detach().numpy()\n",
    "        if img.ndim ==3:\n",
    "            nx,ny = img.shape[1:]\n",
    "            img = img[0,:,:].reshape(nx,ny)\n",
    "    f,ax = plt.subplots(figsize=(10,10))\n",
    "    h,w = img.shape[:2]\n",
    "    ax.set_title(f\"img({h}pix*{w}pix)\")\n",
    "    ax.imshow(img)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "import urllib\n",
    "import cv2\n",
    "import io #Pillowを使って、URLから画像を読みこむ\n",
    "# https://qiita.com/zabeth129/items/b355ebfc82d38bc49778\n",
    "from  PIL import Image\n",
    "\n",
    "def load_sample(ndarray=False):\n",
    "    path = \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\n",
    "#     img = cv2.imread(path)\n",
    "    res = urllib.request.urlopen(path)\n",
    "    if res.code ==200:\n",
    "        f_obj = io.BytesIO(res.read())\n",
    "        img = Image.open(f_obj)\n",
    "        if ndarray:\n",
    "            img = np.array(img)\n",
    "        return img\n",
    "    else:\n",
    "        print(\"Not Data !\",res.code)\n",
    "        return None\n",
    "\n",
    "#     url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "#     try:\n",
    "#         urllib.URLopener().retrieve(url, filename)\n",
    "#     except: \n",
    "#         urllib.request.urlretrieve(url, filename)\n",
    "#     return filename\n",
    "\n",
    "# img = load_sample()\n",
    "# img2 = preprocess(img)\n",
    "# pic_imshow(img2)\n",
    "# img2.size()\n",
    "# type(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_month -> 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((720, 121, 121), 720)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----------------------------------------\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "class OpenNetCDF:\n",
    "    DIR_DATA=\"/work/ysorimachi/era5/dat2\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cele = None\n",
    "        self.mm = None\n",
    "        self.nc = None\n",
    "        \n",
    "    def path(self):\n",
    "    #     high_cloud_cover  low_cloud_cover  mean_sea_level_pressure  medium_cloud_cover\n",
    "        if self.cele == \"hc\":\n",
    "            name = \"high_cloud_cover\"\n",
    "        elif self.cele == \"mc\":\n",
    "            name = \"medium_cloud_cover\"\n",
    "        elif self.cele == \"lc\":\n",
    "            name = \"low_cloud_cover\"\n",
    "        elif self.cele == \"sp\":\n",
    "            name = \"mean_sea_level_pressure\"\n",
    "            \n",
    "        path = f\"{self.DIR_DATA}/{name}/download_{self.mm}.nc\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Not Found {self.mm} !\")\n",
    "            _yy = [ p.split(\"_\")[1][:6] for p in sorted(glob.glob(f\"{self.DIR_DATA}/{name}/*.nc\")) ]\n",
    "            print(_yy)\n",
    "            print(\"-\"*50)\n",
    "            return None\n",
    "        else:\n",
    "            return path\n",
    "    \n",
    "    def load(self,cele,mm):\n",
    "        self.cele = cele\n",
    "        self.mm =mm\n",
    "        \n",
    "        path = self.path()\n",
    "        if path is not None:\n",
    "            nc = Dataset(path, 'r')\n",
    "            self.nc = nc\n",
    "            \n",
    "            data = self._data\n",
    "            if type(data) == netCDF4._netCDF4.Variable:\n",
    "                data = np.array(data)\n",
    "            time = self._time\n",
    "            _lat = self._lat\n",
    "            _lon = self._lon\n",
    "            return data,time,_lat,_lon\n",
    "            \n",
    "        else:\n",
    "            print(\"Not Found !\")\n",
    "    \n",
    "    def load_multi(self,cele,_mm):\n",
    "        _data =[]\n",
    "        _time = []\n",
    "        for mm in tqdm(_mm):\n",
    "            data,time,_lat,_lon = self.load(cele,mm)\n",
    "            _time += time\n",
    "            _data.append(data)\n",
    "        \n",
    "        data = np.concatenate(_data)\n",
    "        return data,_time,_lat,_lon\n",
    "    \n",
    "#     @property\n",
    "    def check(self,cele,mm):\n",
    "        self.cele = cele\n",
    "        self.mm =mm\n",
    "        path = self.path()\n",
    "        if path is not None:\n",
    "            nc = Dataset(path, 'r')\n",
    "        return nc.variables.keys()\n",
    "    \n",
    "    @property\n",
    "    def _data(self):\n",
    "        if self.cele == \"hc\":\n",
    "            k = \"hcc\"\n",
    "        elif self.cele == \"mc\":\n",
    "            k = \"mcc\"\n",
    "        elif self.cele == \"lc\":\n",
    "            k = \"lcc\"\n",
    "        elif self.cele == \"sp\":\n",
    "            k = \"msl\"\n",
    "        return self.nc.variables[k]\n",
    "    \n",
    "    @property\n",
    "    def _time(self):\n",
    "        _t = list(self.nc.variables[\"time\"])\n",
    "        _t = [ self.conv_time(t) for t in _t ]\n",
    "        return _t\n",
    "    \n",
    "    def conv_time(self,t):\n",
    "        init = datetime(1900,1,1,0,0)\n",
    "        return init + timedelta(hours=int(t.data))\n",
    "    \n",
    "    @property\n",
    "    def _lon(self):\n",
    "        _lon = [ float(t.data) for t in self.nc.variables[\"longitude\"] ]\n",
    "        return _lon\n",
    "    @property\n",
    "    def _lat(self):\n",
    "        _lat = [ float(t.data) for t in self.nc.variables[\"latitude\"] ]\n",
    "        return _lat\n",
    "\n",
    "def loop_mm(yy=5):\n",
    "    _mm=[]\n",
    "    for yy in range(2014,2014+yy):\n",
    "        for mm in range(1,12+1):\n",
    "            cmm= str(mm).zfill(2)\n",
    "            _mm.append(f\"{yy}{cmm}\")\n",
    "    print(\"N_month ->\", len(_mm))\n",
    "    return _mm\n",
    "\n",
    "# def_path(\"hc\",\"202012\")\n",
    "nc = OpenNetCDF()\n",
    "_mm=loop_mm()[:3]\n",
    "\n",
    "# data,_t,_lon,_lat = nc.load_multi(\"sp\",_mm)\n",
    "# data.shape,len(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_month -> 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.93it/s]\n"
     ]
    }
   ],
   "source": [
    "def random_idx(st,ed,N):\n",
    "    return sorted(list(np.random.randint(st,ed,N)))\n",
    "\n",
    "def get_time(_idx,_time):\n",
    "    return [ _t[i] for i in _idx]\n",
    "_mm=loop_mm()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mm(cele):\n",
    "    DIR_DATA=\"/work/ysorimachi/era5/dat2\"\n",
    "    if cele == \"hc\":\n",
    "        name = \"high_cloud_cover\"\n",
    "    elif cele == \"mc\":\n",
    "        name = \"medium_cloud_cover\"\n",
    "    elif cele == \"lc\":\n",
    "        name = \"low_cloud_cover\"\n",
    "    elif cele == \"sp\":\n",
    "        name = \"mean_sea_level_pressure\"\n",
    "    \n",
    "    _path = sorted(os.listdir(f\"{DIR_DATA}/{name}\"))\n",
    "    \n",
    "    _yy = [ f.split(\"_\")[1][:6] for f in _path] \n",
    "    return list(_yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pic_imshow(spl[5,:,:])\n",
    "def pic_imshow35(img,list_time,_idx):\n",
    "    _t = get_time(_idx,list_time)\n",
    "    _t = [ t.strftime(\"%Y%m%d %H:%M\") for t in _t]\n",
    "    \n",
    "    f,ax = plt.subplots(5,7,figsize=(7*4,5*4))\n",
    "    ax = ax.flatten()\n",
    "    for i,idx in enumerate(_idx):\n",
    "        img2 = img[idx,:,:]\n",
    "#         print(img2.shape)\n",
    "        ax[i].imshow(img2,vmin=0, vmax=1,cmap=\"seismic\")\n",
    "        h,w = img2.shape\n",
    "        ct = _t[i]\n",
    "        ax[i].set_title(f\"img({h}*{w}) {ct}\")\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "# data,_t,_lon,_lat = nc.load_multi(\"sp\",_mm)\n",
    "_idx = random_idx(0,data.shape[0],35)\n",
    "# pic_imshow35(data,_t,_idx)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "class Scaler:\n",
    "    def __init__(self,name):\n",
    "        self.sc = {}\n",
    "        self.name = name\n",
    "    \n",
    "    def fit_transform(self,data):\n",
    "        for i in range(data.shape[0]):\n",
    "                if self.name == \"minmax\":\n",
    "                    self.sc[i] = MinMaxScaler()\n",
    "                if self.name == \"std\":\n",
    "                    self.sc[i] = StandardScaler()\n",
    "                \n",
    "                data[i,:,:] = self.sc[i].fit_transform(data[i,:,:])\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model の定義でCNNでECMWFの画像について実装していく予定\n",
    "\"\"\"\n",
    "class CNN_ENCODER(nn.Module):\n",
    "    def __init__(self, out_size=16):\n",
    "        super(CNN_ENCODER,self).__init__()\n",
    "        # 入力のinput画像について　56*56で入力\n",
    "        #----------------\n",
    "        #1chan * 56x56　->　8chan * 28x28\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Conv2d(1,8,kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        #----------------\n",
    "        #8chan * 28x28　->　16chan * 14x14\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Conv2d(8,16,kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        #----------------\n",
    "        #16chan * 14x14 -> 32 * 7x7\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        #----------------\n",
    "        #Linear 2 layer\n",
    "        self.l4 = nn.Sequential(\n",
    "            nn.Linear(32*7*7,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,128))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def ResNET(N=18,pretrained=True):\n",
    "    if N==18:\n",
    "        return torchvision.models.resnet18(pretrained= pretrained)\n",
    "    if N==34:\n",
    "        return torchvision.models.resnet34(pretrained= pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "# model = ResNET(34)\n",
    "model = CNN_ENCODER()\n",
    "res18 = ResNET(18)\n",
    "res34 = ResNET(34)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_ENCODER                              --                        --\n",
       "├─Sequential: 1-1                        [16, 8, 28, 28]           --\n",
       "│    └─Conv2d: 2-1                       [16, 8, 56, 56]           208\n",
       "│    └─BatchNorm2d: 2-2                  [16, 8, 56, 56]           16\n",
       "│    └─ReLU: 2-3                         [16, 8, 56, 56]           --\n",
       "│    └─MaxPool2d: 2-4                    [16, 8, 28, 28]           --\n",
       "├─Sequential: 1-2                        [16, 16, 14, 14]          --\n",
       "│    └─Conv2d: 2-5                       [16, 16, 28, 28]          3,216\n",
       "│    └─BatchNorm2d: 2-6                  [16, 16, 28, 28]          32\n",
       "│    └─ReLU: 2-7                         [16, 16, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-8                    [16, 16, 14, 14]          --\n",
       "├─Sequential: 1-3                        [16, 32, 7, 7]            --\n",
       "│    └─Conv2d: 2-9                       [16, 32, 14, 14]          12,832\n",
       "│    └─BatchNorm2d: 2-10                 [16, 32, 14, 14]          64\n",
       "│    └─ReLU: 2-11                        [16, 32, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-12                   [16, 32, 7, 7]            --\n",
       "├─Sequential: 1-4                        [16, 16]                  --\n",
       "│    └─Linear: 2-13                      [16, 128]                 200,832\n",
       "│    └─ReLU: 2-14                        [16, 128]                 --\n",
       "│    └─Linear: 2-15                      [16, 16]                  2,064\n",
       "==========================================================================================\n",
       "Total params: 219,264\n",
       "Trainable params: 219,264\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 94.27\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 11.26\n",
       "Params size (MB): 0.88\n",
       "Estimated Total Size (MB): 12.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model,\n",
    "    input_size=(16,1,56, 56),\n",
    "    col_names=[\"output_size\", \"num_params\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    pre_prs = transforms.Compose([\n",
    "        transforms.Resize(70),\n",
    "        transforms.CenterCrop(56),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#         transforms.Grayscale(num_output_channels=1),\n",
    "    ])\n",
    "    img = pre_prs(img)\n",
    "    # Min -Max Scaler\n",
    "#     https://discuss.pytorch.org/t/how-to-efficiently-normalize-a-batch-of-tensor-to-0-1/65122\n",
    "    \n",
    "    return img\n",
    "\n",
    "def mk_DataLoader(cele,_mm):\n",
    "    nc = OpenNetCDF()\n",
    "    sc = Scaler(\"minmax\")\n",
    "        \n",
    "    data,_time,_,_ = nc.load_multi(cele,_mm)\n",
    "    data = sc.fit_transform(data)\n",
    "    \n",
    "    if type(data) != np.ndarray:\n",
    "        data = np.array(data)\n",
    "    \n",
    "    _img=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        img = data[i,:,:]\n",
    "        \n",
    "        if type(img) != Image.Image:\n",
    "            img = Image.fromarray(img)\n",
    "        img = preprocess(img)\n",
    "        _img.append(img)\n",
    "    \n",
    "    _img = tuple(_img)\n",
    "    _img = torch.stack(_img,0)\n",
    "    return _img,_time\n",
    "\n",
    "# _img,_time = mk_DataLoader(\"sp\",_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 1, 56, 56])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_img = tuple(_img)\n",
    "_img = torch.stack(_img,0)\n",
    "_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 128)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_img,_time = mk_DataLoader(\"sp\",N=3)\n",
    "model = CNN_ENCODER()\n",
    "res = model(_img)\n",
    "res2 = res.detach().numpy()\n",
    "res2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/ysorimachi/work/sori_py2/deepl/py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ysorimachi/work/sori_py2/deepl/jupyter',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python38.zip',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/ysorimachi/.local/lib/python3.8/site-packages',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8/site-packages',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/ysorimachi/.ipython',\n",
       " 'py',\n",
       " '/home/ysorimachi/work/sori_py2/deep/py',\n",
       " '/home/ysorimachi/work/sori_py2/deepl/py']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from som2 import SOM\n",
    "# os.listdir(\"/home/ysorimachi/work/sori_py2/deep/py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans,AgglomerativeClustering\n",
    "# from (self, m=3, n=3, dim=3, lr=1, sigma=1,distance=\"ED\",max_iter=3000, epoch=1)\n",
    "class ClusterModel:\n",
    "    def __init__(self,method,n_clusters=16):\n",
    "        self.method = method\n",
    "        map_size = int(np.sqrt(n_clusters))\n",
    "        \n",
    "        if method==\"kmeans\":\n",
    "            m = KMeans(n_clusters=n_clusters)\n",
    "        if method==\"ward\":\n",
    "            m = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        if method ==\"SOM-ED\":\n",
    "            m = SOM(m=map_size, n=map_size,dim=128,distance=\"ED\")\n",
    "        if method == \"SOM-SSIM\":\n",
    "            m = SOM(m=map_size, n=map_size,dim=128,distance=\"SSIM\")\n",
    "        self.model = m\n",
    "        self.isTrained = 0\n",
    "        \n",
    "    def fit(self,X):\n",
    "        self.model.fit(X)\n",
    "        self.isTrained = 1\n",
    "        self.X = X\n",
    "        \n",
    "    @property\n",
    "    def labels(self):\n",
    "        if self.method==\"kmeans\" or self.method==\"ward\":\n",
    "            lbl = pd.Series(self.model.labels_,name = \"labels\")\n",
    "        else:\n",
    "#             print(\"SOM\")\n",
    "            lbl = self.model.predict(self.X)\n",
    "            lbl = pd.Series(lbl,name=\"labels\")\n",
    "        return lbl \n",
    "        \n",
    "    def predict(self,X):\n",
    "        if self.isTrained == 1:\n",
    "            pred = self.model.predict(X)\n",
    "        else:\n",
    "            self.fit(X)\n",
    "            pred = self.model.predict(X)\n",
    "            \n",
    "        pred = pd.Series(pred,name = \"pred\")\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "715    13\n",
       "716    13\n",
       "717    13\n",
       "718    13\n",
       "719    13\n",
       "Name: labels, Length: 720, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ClusterModel(\"ward\")\n",
    "m.fit(res2)\n",
    "m.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "_img,_time = mk_DataLoader(\"sp\",N=3)\n",
    "model = CNN_ENCODER()\n",
    "res = model(_img)\n",
    "res2 = res.detach().numpy()\n",
    "res2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:27<00:00,  8.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([58440, 1, 56, 56])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mm = check_mm(\"sp\")[:12*18]\n",
    "_img,_time = mk_DataLoader(\"sp\",_mm)\n",
    "_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_ENCODER()\n",
    "res = model(_img)\n",
    "res2 = res.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:25<00:00,  8.91it/s]\n",
      "100%|██████████| 4/4 [09:08<00:00, 137.08s/it]\n",
      "100%|██████████| 228/228 [01:24<00:00,  2.69it/s]\n",
      "100%|██████████| 4/4 [11:45<00:00, 176.25s/it]\n",
      "100%|██████████| 228/228 [01:41<00:00,  2.24it/s]\n",
      "100%|██████████| 4/4 [10:03<00:00, 150.87s/it]\n",
      "100%|██████████| 228/228 [01:38<00:00,  2.30it/s]\n",
      "100%|██████████| 4/4 [10:41<00:00, 160.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "DIR=\"/home/ysorimachi/work/ecmwf/out/cluster210930/label/cnn\"\n",
    "def loop_train(n_month=6):\n",
    "    for cate in [ \"sp\",\"hc\",\"mc\",\"lc\"]:\n",
    "        _mm = check_mm(cate)[:n_month]\n",
    "        _img,_time = mk_DataLoader(cate,_mm)\n",
    "        #model create---\n",
    "        model = CNN_ENCODER()\n",
    "        res = model(_img) # forward calc\n",
    "        res2 = res.detach().numpy()\n",
    "#         print(cate, len(_mm))\n",
    "        #------------\n",
    "        _model,_lbl=[],[]\n",
    "        df = pd.DataFrame()\n",
    "        df[\"time\"] =_time\n",
    "\n",
    "        for name in tqdm([\"kmeans\",\"ward\",\"SOM-ED\",\"SOM-SSIM\"]):\n",
    "            m = ClusterModel(name)\n",
    "            m.fit(res2)\n",
    "            lbl = m.labels\n",
    "            lbl.name = name\n",
    "            \n",
    "            #model save\n",
    "            model_path = f\"{DIR}/cluster_{cate}_{name}.pkl\"\n",
    "            with open(model_path, 'wb') as pkl:\n",
    "                pickle.dump(m, pkl)\n",
    "            _lbl.append(lbl)\n",
    "\n",
    "        df = pd.concat([df] + _lbl,axis=1)\n",
    "        df.to_csv(f\"{DIR}/label_{cate}.csv\",index=False)\n",
    "        \n",
    "loop_train(n_month=12*19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
