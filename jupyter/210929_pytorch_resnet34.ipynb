{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## jupyter notebook に最初に記述tenplate\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "2021.09.27 今回参考にしたものについて\r\n",
    "https://qiita.com/ku_a_i/items/0ea4b93d767ce7c83145\r\n",
    "\r\n",
    "2021.09.29 - Res-Net34について\r\n",
    "https://pytorch.org/hub/pytorch_vision_resnet/\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "### ------------------------------------------------\r\n",
    "# basic-module\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys,os,re,glob\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime, timedelta\r\n",
    "import warnings\r\n",
    "warnings.simplefilter('ignore')\r\n",
    "from tqdm import tqdm\r\n",
    "import seaborn as sns\r\n",
    "# sori -module\r\n",
    "# sys.path.append('/home/ysorimachi/tool')\r\n",
    "# from getErrorValues import me,rmse,mae,r2 #(x,y)\r\n",
    "# from convSokuhouData import conv_sfc #(df, ave=minutes,hour)\r\n",
    "\r\n",
    "# #---------------------------------------------------\r\n",
    "# import subprocess\r\n",
    "# import requests\r\n",
    "# #--------------------------\r\n",
    "# import pickle\r\n",
    "# import gzip\r\n",
    "# from pathlib import Path\r\n",
    "\r\n",
    "# deep learning modules \r\n",
    "# imports\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\r\n",
    "import torchvision\r\n",
    "from torchvision import transforms\r\n",
    "from torchinfo import summary #torchinfoはニューラルネットの中身を見れるのでおすすめ"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#参考の資料について\r\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\r\n",
    "\r\n",
    "def load_df(path, isDAY=True):\r\n",
    "    df = pd.read_csv(path)\r\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\r\n",
    "    df[\"dd\"] = df[\"time\"].apply(lambda x: x.strftime(\"%Y%m%d\"))\r\n",
    "    df[\"hh\"] = df[\"time\"].apply(lambda x: x.strftime(\"%H\"))\r\n",
    "    \r\n",
    "    if isDAY:\r\n",
    "        df = df.groupby(\"dd\").agg({\"DEMAND(10^4kW)\" : \"mean\"})\r\n",
    "    return df\r\n",
    "\r\n",
    "def plot_df(df,_col):\r\n",
    "    f,ax = plt.subplots(figsize=(18,8))\r\n",
    "    for c in _col:\r\n",
    "        ax.plot(df[c],label=c)\r\n",
    "    \r\n",
    "    ax.legend(loc=\"upper right\")\r\n",
    "    plt.show()\r\n",
    "    return\r\n",
    "\r\n",
    "def cut_time(df,st,ed=None):\r\n",
    "    if ed:\r\n",
    "        return df[(df[\"time\"]>=st)&(df[\"time\"]<=ed)]\r\n",
    "    else:\r\n",
    "        return df[df[\"time\"]>=st]\r\n",
    "\r\n",
    "def move_ave(df,col,lag=7):\r\n",
    "    new_col  = f\"MA{lag}_{col}\"\r\n",
    "    df[new_col]= df[col].rolling(lag).mean()\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\"\"\"\r\n",
    "import torch ResNet pretrained model \r\n",
    "\"\"\"\r\n",
    "import torchvision\r\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\r\n",
    "# model = torchvision.models.resnet18(pretrained= True)\r\n",
    "# model = torchvision.models.resnet34(pretrained= True)\r\n",
    "# or any of these variants\r\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\r\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\r\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\r\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\r\n",
    "def load_resnet(N=18,pretrained=True):\r\n",
    "    if N==18:\r\n",
    "        return torchvision.models.resnet18(pretrained= pretrained)\r\n",
    "    if N==34:\r\n",
    "        return torchvision.models.resnet34(pretrained= pretrained)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def pic_imshow(img):\r\n",
    "    if type(img)== torch.Tensor:\r\n",
    "        img = img.to('cpu').detach().numpy()\r\n",
    "        if img.ndim ==3:\r\n",
    "            nx,ny = img.shape[1:]\r\n",
    "            img = img[0,:,:].reshape(nx,ny)\r\n",
    "    f,ax = plt.subplots(figsize=(10,10))\r\n",
    "    h,w = img.shape[:2]\r\n",
    "    ax.set_title(f\"img({h}pix*{w}pix)\")\r\n",
    "    ax.imshow(img)\r\n",
    "    plt.show()\r\n",
    "    return\r\n",
    "\r\n",
    "\r\n",
    "import urllib\r\n",
    "import cv2\r\n",
    "import io #Pillowを使って、URLから画像を読みこむ\r\n",
    "# https://qiita.com/zabeth129/items/b355ebfc82d38bc49778\r\n",
    "from  PIL import Image\r\n",
    "\r\n",
    "def load_sample(ndarray=False):\r\n",
    "    path = \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\r\n",
    "#     img = cv2.imread(path)\r\n",
    "    res = urllib.request.urlopen(path)\r\n",
    "    if res.code ==200:\r\n",
    "        f_obj = io.BytesIO(res.read())\r\n",
    "        img = Image.open(f_obj)\r\n",
    "        if ndarray:\r\n",
    "            img = np.array(img)\r\n",
    "        return img\r\n",
    "    else:\r\n",
    "        print(\"Not Data !\",res.code)\r\n",
    "        return None\r\n",
    "\r\n",
    "#     url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\r\n",
    "#     try:\r\n",
    "#         urllib.URLopener().retrieve(url, filename)\r\n",
    "#     except: \r\n",
    "#         urllib.request.urlretrieve(url, filename)\r\n",
    "#     return filename\r\n",
    "\r\n",
    "# img = load_sample()\r\n",
    "# img2 = preprocess(img)\r\n",
    "# pic_imshow(img2)\r\n",
    "# img2.size()\r\n",
    "# type(img2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#-----------------------------------------\r\n",
    "import netCDF4\r\n",
    "from netCDF4 import Dataset\r\n",
    "class OpenNetCDF:\r\n",
    "    DIR_DATA=\"/work/ysorimachi/era5/dat2\"\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        self.cele = None\r\n",
    "        self.mm = None\r\n",
    "        self.nc = None\r\n",
    "        \r\n",
    "    def path(self):\r\n",
    "    #     high_cloud_cover  low_cloud_cover  mean_sea_level_pressure  medium_cloud_cover\r\n",
    "        if self.cele == \"hc\":\r\n",
    "            name = \"high_cloud_cover\"\r\n",
    "        elif self.cele == \"mc\":\r\n",
    "            name = \"medium_cloud_cover\"\r\n",
    "        elif self.cele == \"lc\":\r\n",
    "            name = \"low_cloud_cover\"\r\n",
    "        elif self.cele == \"sp\":\r\n",
    "            name = \"mean_sea_level_pressure\"\r\n",
    "            \r\n",
    "        path = f\"{self.DIR_DATA}/{name}/download_{self.mm}.nc\"\r\n",
    "        return path\r\n",
    "    \r\n",
    "    def load(self,cele,mm):\r\n",
    "        self.cele = cele\r\n",
    "        self.mm =mm\r\n",
    "        \r\n",
    "        path = self.path()\r\n",
    "        if path is not None:\r\n",
    "            nc = Dataset(path, 'r')\r\n",
    "            self.nc = nc\r\n",
    "            \r\n",
    "            data = self._data\r\n",
    "            if type(data) == netCDF4._netCDF4.Variable:\r\n",
    "                data = np.array(data)\r\n",
    "            time = self._time\r\n",
    "            _lat = self._lat\r\n",
    "            _lon = self._lon\r\n",
    "            return data,time,_lat,_lon\r\n",
    "            \r\n",
    "        else:\r\n",
    "            print(\"Not Found !\")\r\n",
    "    \r\n",
    "    def load_multi(self,cele,_mm):\r\n",
    "        _data =[]\r\n",
    "        _time = []\r\n",
    "        for mm in tqdm(_mm):\r\n",
    "            data,time,_lat,_lon = self.load(cele,mm)\r\n",
    "            _time += time\r\n",
    "            _data.append(data)\r\n",
    "        \r\n",
    "        data = np.concatenate(_data)\r\n",
    "        return data,_time,_lat,_lon\r\n",
    "    \r\n",
    "#     @property\r\n",
    "    def check(self,cele,mm):\r\n",
    "        self.cele = cele\r\n",
    "        self.mm =mm\r\n",
    "        path = self.path()\r\n",
    "        if path is not None:\r\n",
    "            nc = Dataset(path, 'r')\r\n",
    "        return nc.variables.keys()\r\n",
    "    \r\n",
    "    @property\r\n",
    "    def _data(self):\r\n",
    "        if self.cele == \"hc\":\r\n",
    "            k = \"hcc\"\r\n",
    "        elif self.cele == \"mc\":\r\n",
    "            k = \"mcc\"\r\n",
    "        elif self.cele == \"lc\":\r\n",
    "            k = \"lcc\"\r\n",
    "        elif self.cele == \"sp\":\r\n",
    "            k = \"msl\"\r\n",
    "        return self.nc.variables[k]\r\n",
    "    \r\n",
    "    @property\r\n",
    "    def _time(self):\r\n",
    "        _t = list(self.nc.variables[\"time\"])\r\n",
    "        _t = [ self.conv_time(t) for t in _t ]\r\n",
    "        return _t\r\n",
    "    \r\n",
    "    def conv_time(self,t):\r\n",
    "        init = datetime(1900,1,1,0,0)\r\n",
    "        return init + timedelta(hours=int(t.data))\r\n",
    "    \r\n",
    "    @property\r\n",
    "    def _lon(self):\r\n",
    "        _lon = [ float(t.data) for t in self.nc.variables[\"longitude\"] ]\r\n",
    "        return _lon\r\n",
    "    @property\r\n",
    "    def _lat(self):\r\n",
    "        _lat = [ float(t.data) for t in self.nc.variables[\"latitude\"] ]\r\n",
    "        return _lat\r\n",
    "\r\n",
    "def loop_mm(yy=5):\r\n",
    "    _mm=[]\r\n",
    "    for yy in range(2014,2014+yy):\r\n",
    "        for mm in range(1,12+1):\r\n",
    "            cmm= str(mm).zfill(2)\r\n",
    "            _mm.append(f\"{yy}{cmm}\")\r\n",
    "    print(\"N_month ->\", len(_mm))\r\n",
    "    return _mm\r\n",
    "\r\n",
    "# def_path(\"hc\",\"202012\")\r\n",
    "nc = OpenNetCDF()\r\n",
    "_mm=loop_mm()[:3]\r\n",
    "\r\n",
    "# data,_t,_lon,_lat = nc.load_multi(\"sp\",_mm)\r\n",
    "# data.shape,len(_t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00, 11.22it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N_month -> 60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((720, 121, 121), 720)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def random_idx(st,ed,N):\r\n",
    "    return sorted(list(np.random.randint(st,ed,N)))\r\n",
    "\r\n",
    "def get_time(_idx,_time):\r\n",
    "    return [ _t[i] for i in _idx]\r\n",
    "_mm=loop_mm()[:5]\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00, 13.81it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N_month -> 60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.93it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "def check_mm(cele):\r\n",
    "    DIR_DATA=\"/work/ysorimachi/era5/dat2\"\r\n",
    "    if cele == \"hc\":\r\n",
    "        name = \"high_cloud_cover\"\r\n",
    "    elif cele == \"mc\":\r\n",
    "        name = \"medium_cloud_cover\"\r\n",
    "    elif cele == \"lc\":\r\n",
    "        name = \"low_cloud_cover\"\r\n",
    "    elif cele == \"sp\":\r\n",
    "        name = \"mean_sea_level_pressure\"\r\n",
    "    \r\n",
    "    _path = sorted(os.listdir(f\"{DIR_DATA}/{name}\"))\r\n",
    "    \r\n",
    "    _yy = [ f.split(\"_\")[1][:6] for f in _path] \r\n",
    "    return list(_yy)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# pic_imshow(spl[5,:,:])\r\n",
    "def pic_imshow35(img,list_time,_idx):\r\n",
    "    _t = get_time(_idx,list_time)\r\n",
    "    _t = [ t.strftime(\"%Y%m%d %H:%M\") for t in _t]\r\n",
    "    \r\n",
    "    f,ax = plt.subplots(5,7,figsize=(7*4,5*4))\r\n",
    "    ax = ax.flatten()\r\n",
    "    for i,idx in enumerate(_idx):\r\n",
    "        img2 = img[idx,:,:]\r\n",
    "#         print(img2.shape)\r\n",
    "        ax[i].imshow(img2,vmin=0, vmax=1,cmap=\"seismic\")\r\n",
    "        h,w = img2.shape\r\n",
    "        ct = _t[i]\r\n",
    "        ax[i].set_title(f\"img({h}*{w}) {ct}\")\r\n",
    "    plt.show()\r\n",
    "    return \r\n",
    "\r\n",
    "\r\n",
    "# data,_t,_lon,_lat = nc.load_multi(\"sp\",_mm)\r\n",
    "_idx = random_idx(0,data.shape[0],35)\r\n",
    "# pic_imshow35(data,_t,_idx)\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "class Scaler:\r\n",
    "    def __init__(self,name):\r\n",
    "        self.sc = {}\r\n",
    "        self.name = name\r\n",
    "    \r\n",
    "    def fit_transform(self,data):\r\n",
    "        for i in range(data.shape[0]):\r\n",
    "                if self.name == \"minmax\":\r\n",
    "                    self.sc[i] = MinMaxScaler()\r\n",
    "                if self.name == \"std\":\r\n",
    "                    self.sc[i] = StandardScaler()\r\n",
    "                \r\n",
    "                data[i,:,:] = self.sc[i].fit_transform(data[i,:,:])\r\n",
    "        \r\n",
    "        return data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "\"\"\"\r\n",
    "model の定義でCNNでECMWFの画像について実装していく予定\r\n",
    "\"\"\"\r\n",
    "class CNN_ENCODER(nn.Module):\r\n",
    "    def __init__(self, out_size=16):\r\n",
    "        super(CNN_ENCODER,self).__init__()\r\n",
    "        # 入力のinput画像について　56*56で入力\r\n",
    "        #----------------\r\n",
    "        #1chan * 56x56　->　8chan * 28x28\r\n",
    "        self.l1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1,8,kernel_size=5, padding=2),\r\n",
    "            nn.BatchNorm2d(8),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2))\r\n",
    "        #----------------\r\n",
    "        #8chan * 28x28　->　16chan * 14x14\r\n",
    "        self.l2 = nn.Sequential(\r\n",
    "            nn.Conv2d(8,16,kernel_size=5, padding=2),\r\n",
    "            nn.BatchNorm2d(16),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2))\r\n",
    "        #----------------\r\n",
    "        #16chan * 14x14 -> 32 * 7x7\r\n",
    "        self.l3 = nn.Sequential(\r\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\r\n",
    "            nn.BatchNorm2d(32),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(2))\r\n",
    "        #----------------\r\n",
    "        #Linear 2 layer\r\n",
    "        self.l4 = nn.Sequential(\r\n",
    "            nn.Linear(32*7*7,512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512,128))\r\n",
    "        \r\n",
    "    def forward(self,x):\r\n",
    "        x = self.l1(x)\r\n",
    "        x = self.l2(x)\r\n",
    "        x = self.l3(x)\r\n",
    "        \r\n",
    "        x = x.view(x.size(0),-1)\r\n",
    "        x = self.l4(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "    \r\n",
    "def ResNET(N=18,pretrained=True):\r\n",
    "    if N==18:\r\n",
    "        return torchvision.models.resnet18(pretrained= pretrained)\r\n",
    "    if N==34:\r\n",
    "        return torchvision.models.resnet34(pretrained= pretrained)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "#summary\r\n",
    "# model = ResNET(34)\r\n",
    "model = CNN_ENCODER()\r\n",
    "res18 = ResNET(18)\r\n",
    "res34 = ResNET(34)\r\n",
    "# model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "summary(\r\n",
    "    model,\r\n",
    "    input_size=(16,1,56, 56),\r\n",
    "    col_names=[\"output_size\", \"num_params\"]\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN_ENCODER                              --                        --\n",
       "├─Sequential: 1-1                        [16, 8, 28, 28]           --\n",
       "│    └─Conv2d: 2-1                       [16, 8, 56, 56]           208\n",
       "│    └─BatchNorm2d: 2-2                  [16, 8, 56, 56]           16\n",
       "│    └─ReLU: 2-3                         [16, 8, 56, 56]           --\n",
       "│    └─MaxPool2d: 2-4                    [16, 8, 28, 28]           --\n",
       "├─Sequential: 1-2                        [16, 16, 14, 14]          --\n",
       "│    └─Conv2d: 2-5                       [16, 16, 28, 28]          3,216\n",
       "│    └─BatchNorm2d: 2-6                  [16, 16, 28, 28]          32\n",
       "│    └─ReLU: 2-7                         [16, 16, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-8                    [16, 16, 14, 14]          --\n",
       "├─Sequential: 1-3                        [16, 32, 7, 7]            --\n",
       "│    └─Conv2d: 2-9                       [16, 32, 14, 14]          12,832\n",
       "│    └─BatchNorm2d: 2-10                 [16, 32, 14, 14]          64\n",
       "│    └─ReLU: 2-11                        [16, 32, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-12                   [16, 32, 7, 7]            --\n",
       "├─Sequential: 1-4                        [16, 16]                  --\n",
       "│    └─Linear: 2-13                      [16, 128]                 200,832\n",
       "│    └─ReLU: 2-14                        [16, 128]                 --\n",
       "│    └─Linear: 2-15                      [16, 16]                  2,064\n",
       "==========================================================================================\n",
       "Total params: 219,264\n",
       "Trainable params: 219,264\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 94.27\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 11.26\n",
       "Params size (MB): 0.88\n",
       "Estimated Total Size (MB): 12.34\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "def preprocess(img):\r\n",
    "    pre_prs = transforms.Compose([\r\n",
    "        transforms.Resize(70),\r\n",
    "        transforms.CenterCrop(56),\r\n",
    "        transforms.ToTensor(),\r\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\r\n",
    "#         transforms.Grayscale(num_output_channels=1),\r\n",
    "    ])\r\n",
    "    img = pre_prs(img)\r\n",
    "    # Min -Max Scaler\r\n",
    "#     https://discuss.pytorch.org/t/how-to-efficiently-normalize-a-batch-of-tensor-to-0-1/65122\r\n",
    "    \r\n",
    "    return img\r\n",
    "\r\n",
    "def mk_DataLoader(cele,_mm):\r\n",
    "    nc = OpenNetCDF()\r\n",
    "    sc = Scaler(\"minmax\")\r\n",
    "        \r\n",
    "    data,_time,_,_ = nc.load_multi(cele,_mm)\r\n",
    "    data = sc.fit_transform(data)\r\n",
    "    \r\n",
    "    if type(data) != np.ndarray:\r\n",
    "        data = np.array(data)\r\n",
    "    \r\n",
    "    _img=[]\r\n",
    "    for i in range(data.shape[0]):\r\n",
    "        img = data[i,:,:]\r\n",
    "        \r\n",
    "        if type(img) != Image.Image:\r\n",
    "            img = Image.fromarray(img)\r\n",
    "        img = preprocess(img)\r\n",
    "        _img.append(img)\r\n",
    "    \r\n",
    "    _img = tuple(_img)\r\n",
    "    _img = torch.stack(_img,0)\r\n",
    "    return _img,_time\r\n",
    "\r\n",
    "# _img,_time = mk_DataLoader(\"sp\",_mm)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "_img = tuple(_img)\r\n",
    "_img = torch.stack(_img,0)\r\n",
    "_img.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([720, 1, 56, 56])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "\r\n",
    "_img,_time = mk_DataLoader(\"sp\",N=3)\r\n",
    "model = CNN_ENCODER()\r\n",
    "res = model(_img)\r\n",
    "res2 = res.detach().numpy()\r\n",
    "res2.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(720, 128)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "sys.path.append(\"/home/ysorimachi/work/sori_py2/deepl/py\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "sys.path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/ysorimachi/work/sori_py2/deepl/jupyter',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python38.zip',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/ysorimachi/.local/lib/python3.8/site-packages',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8/site-packages',\n",
       " '/home/ysorimachi/.conda/envs/sori_torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/ysorimachi/.ipython',\n",
       " 'py',\n",
       " '/home/ysorimachi/work/sori_py2/deep/py',\n",
       " '/home/ysorimachi/work/sori_py2/deepl/py']"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "from som2 import SOM\r\n",
    "# os.listdir(\"/home/ysorimachi/work/sori_py2/deep/py\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "from som2 import SOM\r\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering\r\n",
    "# from (self, m=3, n=3, dim=3, lr=1, sigma=1,distance=\"ED\",max_iter=3000, epoch=1)\r\n",
    "class ClusterModel:\r\n",
    "    def __init__(self,method,n_clusters=16):\r\n",
    "        self.method = method\r\n",
    "        map_size = int(np.sqrt(n_clusters))\r\n",
    "        \r\n",
    "        if method==\"kmeans\":\r\n",
    "            m = KMeans(n_clusters=n_clusters)\r\n",
    "        if method==\"ward\":\r\n",
    "            m = AgglomerativeClustering(n_clusters=n_clusters)\r\n",
    "        if method ==\"SOM-ED\":\r\n",
    "            m = SOM(m=map_size, n=map_size,dim=128,distance=\"ED\")\r\n",
    "        if method == \"SOM-SSIM\":\r\n",
    "            m = SOM(m=map_size, n=map_size,dim=128,distance=\"SSIM\")\r\n",
    "        self.model = m\r\n",
    "        self.isTrained = 0\r\n",
    "        \r\n",
    "    def fit(self,X):\r\n",
    "        self.model.fit(X)\r\n",
    "        self.isTrained = 1\r\n",
    "        self.X = X\r\n",
    "        \r\n",
    "    @property\r\n",
    "    def labels(self):\r\n",
    "        if self.method==\"kmeans\" or self.method==\"ward\":\r\n",
    "            lbl = pd.Series(self.model.labels_,name = \"labels\")\r\n",
    "        else:\r\n",
    "#             print(\"SOM\")\r\n",
    "            lbl = self.model.predict(self.X)\r\n",
    "            lbl = pd.Series(lbl,name=\"labels\")\r\n",
    "        return lbl \r\n",
    "        \r\n",
    "    def predict(self,X):\r\n",
    "        if self.isTrained == 1:\r\n",
    "            pred = self.model.predict(X)\r\n",
    "        else:\r\n",
    "            self.fit(X)\r\n",
    "            pred = self.model.predict(X)\r\n",
    "            \r\n",
    "        pred = pd.Series(pred,name = \"pred\")\r\n",
    "        return pred\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "m = ClusterModel(\"ward\")\r\n",
    "m.fit(res2)\r\n",
    "m.labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "715    13\n",
       "716    13\n",
       "717    13\n",
       "718    13\n",
       "719    13\n",
       "Name: labels, Length: 720, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "_img,_time = mk_DataLoader(\"sp\",N=3)\n",
    "model = CNN_ENCODER()\n",
    "res = model(_img)\n",
    "res2 = res.detach().numpy()\n",
    "res2.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "_mm = check_mm(\"sp\")[:12*18]\n",
    "_img,_time = mk_DataLoader(\"sp\",_mm)\n",
    "_img.size()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 240/240 [00:27<00:00,  8.67it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([58440, 1, 56, 56])"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "model = CNN_ENCODER()\n",
    "res = model(_img)\n",
    "res2 = res.detach().numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "import pickle\n",
    "DIR=\"/home/ysorimachi/work/ecmwf/out/cluster210930/label/cnn\"\n",
    "def loop_train(n_month=6):\n",
    "    for cate in [ \"sp\",\"hc\",\"mc\",\"lc\"]:\n",
    "        _mm = check_mm(cate)[:n_month]\n",
    "        _img,_time = mk_DataLoader(cate,_mm)\n",
    "        #model create---\n",
    "        model = CNN_ENCODER()\n",
    "        res = model(_img) # forward calc\n",
    "        res2 = res.detach().numpy()\n",
    "#         print(cate, len(_mm))\n",
    "        #------------\n",
    "        _model,_lbl=[],[]\n",
    "        df = pd.DataFrame()\n",
    "        df[\"time\"] =_time\n",
    "\n",
    "        for name in tqdm([\"kmeans\",\"ward\",\"SOM-ED\",\"SOM-SSIM\"]):\n",
    "            m = ClusterModel(name)\n",
    "            m.fit(res2)\n",
    "            lbl = m.labels\n",
    "            lbl.name = name\n",
    "            \n",
    "            #model save\n",
    "            model_path = f\"{DIR}/cluster_{cate}_{name}.pkl\"\n",
    "            with open(model_path, 'wb') as pkl:\n",
    "                pickle.dump(m, pkl)\n",
    "            _lbl.append(lbl)\n",
    "\n",
    "        df = pd.concat([df] + _lbl,axis=1)\n",
    "        df.to_csv(f\"{DIR}/label_{cate}.csv\",index=False)\n",
    "        \n",
    "loop_train(n_month=12*19)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 228/228 [00:25<00:00,  8.91it/s]\n",
      "100%|██████████| 4/4 [09:08<00:00, 137.08s/it]\n",
      "100%|██████████| 228/228 [01:24<00:00,  2.69it/s]\n",
      "100%|██████████| 4/4 [11:45<00:00, 176.25s/it]\n",
      "100%|██████████| 228/228 [01:41<00:00,  2.24it/s]\n",
      "100%|██████████| 4/4 [10:03<00:00, 150.87s/it]\n",
      "100%|██████████| 228/228 [01:38<00:00,  2.30it/s]\n",
      "100%|██████████| 4/4 [10:41<00:00, 160.44s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}